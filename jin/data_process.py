# -*- coding: utf-8 -*-
"""
ì™¸êµ­ì¸ ìž…êµ­ìž ë°ì´í„° ì „ì²˜ë¦¬ ìŠ¤í¬ë¦½íŠ¸ (ì½”ë¡œë‚˜ ì‹œê¸° í¬í•¨)
Author: Jin
Created: 2025-01-15

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ë‹¤ìŒê³¼ ê°™ì€ ì „ì²˜ë¦¬ ìž‘ì—…ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤:
1. ì›ë³¸ ë°ì´í„° ë¡œë“œ ë° ê¸°ë³¸ í´ë¦¬ë‹
2. ì†Œê³„/í•©ê³„/êµí¬/ì†Œê°œ ë“± ë¶ˆí•„ìš”í•œ í•­ëª© ì œê±° (ë”¥ëŸ¬ë‹ ëª¨ë¸ì— ë¶ˆí•„ìš”)
3. Long formatìœ¼ë¡œ ë³€í™˜ (ë”¥ëŸ¬ë‹ ëª¨ë¸ì— ì í•©)
4. ì‹œê³„ì—´ íŠ¹ì„± ë³€ìˆ˜ ìƒì„±
5. ìµœì¢… ì „ì²˜ë¦¬ ë°ì´í„° ì €ìž¥
"""

import pandas as pd
import numpy as np
import os
from datetime import datetime
import warnings

warnings.filterwarnings("ignore")


class ForeignVisitorDataProcessor:
    """ì™¸êµ­ì¸ ìž…êµ­ìž ë°ì´í„° ì „ì²˜ë¦¬ í´ëž˜ìŠ¤"""

    def __init__(
        self,
        input_file="../han/data/1_2_(ë¡œìš°ë°ì´í„°_í•©ë³¸.csv)ëª©ì ë³„_êµ­ì ë³„_ìž…êµ­(05ë…„1ì›”~25ë…„5ì›”).csv",
    ):
        """
        ì´ˆê¸°í™” í•¨ìˆ˜

        Args:
            input_file (str): ìž…ë ¥ íŒŒì¼ ê²½ë¡œ
        """
        self.input_file = input_file
        self.output_dir = "./data/processed/"
        self.raw_data = None
        self.processed_data = None

        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs(self.output_dir, exist_ok=True)

    def load_data(self):
        """
        ë°ì´í„° ë¡œë“œ í•¨ìˆ˜ (ì—¬ëŸ¬ ì¸ì½”ë”© ì‹œë„)

        Returns:
            bool: ë¡œë“œ ì„±ê³µ ì—¬ë¶€
        """
        encodings_to_try = ["utf-8", "cp949", "euc-kr", "latin-1"]

        for encoding in encodings_to_try:
            try:
                print(f"ðŸ“‚ '{encoding}' ì¸ì½”ë”©ìœ¼ë¡œ ë°ì´í„° ë¡œë“œ ì‹œë„ ì¤‘...")
                self.raw_data = pd.read_csv(self.input_file, encoding=encoding)
                print(
                    f"âœ… ë°ì´í„° ë¡œë“œ ì„±ê³µ! ({self.raw_data.shape[0]}í–‰ Ã— {self.raw_data.shape[1]}ì—´)"
                )
                return True
            except Exception as e:
                print(f"âŒ '{encoding}' ì¸ì½”ë”© ì‹¤íŒ¨: {str(e)}")
                continue

        print("âŒ ëª¨ë“  ì¸ì½”ë”© ì‹œë„ ì‹¤íŒ¨")
        return False

    def clean_data(self):
        """
        ë°ì´í„° í´ë¦¬ë‹ í•¨ìˆ˜
        """
        print("\nðŸ§¹ ë°ì´í„° í´ë¦¬ë‹ ì‹œìž‘...")

        # ë°ì´í„°ê°€ ë¡œë“œë˜ì—ˆëŠ”ì§€ í™•ì¸
        if self.raw_data is None:
            print("âŒ ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return

        # ë‘ ë²ˆì§¸ í–‰(ë‹¨ìœ„ ì •ë³´) ì œê±°
        if len(self.raw_data) > 1:
            # ë‘ ë²ˆì§¸ í–‰ì´ ë‹¨ìœ„ ì •ë³´ì¸ì§€ í™•ì¸
            second_row = self.raw_data.iloc[1]
            if pd.isna(second_row.iloc[0]) or "ì¸ì›(ëª…)" in str(second_row.iloc[2]):
                self.raw_data = self.raw_data.drop(self.raw_data.index[1])
                self.raw_data = self.raw_data.reset_index(drop=True)
                print("âœ… ë‹¨ìœ„ ì •ë³´ í–‰ ì œê±° ì™„ë£Œ")

        # ì»¬ëŸ¼ëª…ì´ ì´ë¯¸ 'êµ­ì ', 'ëª©ì 'ìœ¼ë¡œ ë˜ì–´ ìžˆëŠ”ì§€ í™•ì¸
        if "êµ­ì " not in self.raw_data.columns or "ëª©ì " not in self.raw_data.columns:
            # ì²« ë²ˆì§¸ì™€ ë‘ ë²ˆì§¸ ì»¬ëŸ¼ì„ êµ­ì , ëª©ì ìœ¼ë¡œ ì„¤ì •
            columns = list(self.raw_data.columns)
            columns[0] = "êµ­ì "
            columns[1] = "ëª©ì "
            self.raw_data.columns = columns

        # NaN ê°’ì´ ìžˆëŠ” í–‰ ì œê±°
        self.raw_data = self.raw_data.dropna(subset=["êµ­ì ", "ëª©ì "])

        # ê³µë°± ë¬¸ìž ì œê±° (ì–‘ë + ì¤‘ê°„ ê³µë°± ì •ë¦¬)
        self.raw_data["êµ­ì "] = (
            self.raw_data["êµ­ì "].astype(str).str.strip().str.replace(r"\s+", "", regex=True)
        )
        self.raw_data["ëª©ì "] = (
            self.raw_data["ëª©ì "].astype(str).str.strip().str.replace(r"\s+", "", regex=True)
        )

        print(f"âœ… ê¸°ë³¸ í´ë¦¬ë‹ ì™„ë£Œ: {self.raw_data.shape[0]}í–‰")

    def remove_aggregated_rows(self):
        """
        ì†Œê³„/í•©ê³„/êµí¬/ì†Œê°œ ë“± ë¶ˆí•„ìš”í•œ í–‰ ì œê±°
        """
        print("\nðŸ—‘ï¸ ì†Œê³„/í•©ê³„/ë¶ˆí•„ìš”í•œ í•­ëª© ì œê±° ì¤‘...")

        # ì œê±°í•  í‚¤ì›Œë“œ ëª©ë¡ (ë”¥ëŸ¬ë‹ ëª¨ë¸ì— ë¶ˆí•„ìš”í•œ ì§‘ê³„ì„± ë°ì´í„°)
        keywords_to_remove = [
            "ì†Œ ê³„",
            "ì†Œê³„",
            "í•© ê³„",
            "í•©ê³„",
            "ê³„",
            "êµí¬",
            "ì†Œê°œ",
            "ì•„ì‹œì•„ì£¼",
            "ë¯¸ ì£¼",
            "êµ¬ ì£¼",
            "ì•„í”„ë¦¬ì¹´ì£¼",
            "ì˜¤ì„¸ì•„ë‹ˆì•„ì£¼",
            "ê¸°íƒ€",
            "ë¯¸ì£¼",
            "êµ¬ì£¼",
            "ì•„ì‹œì•„",
            "ì•„í”„ë¦¬ì¹´",
            "ì˜¤ì„¸ì•„ë‹ˆì•„",
            "ì „ì²´",
            "ì´ê³„",
            "ì´ ê³„",
            "ì „ ì²´",
        ]

        original_count = len(self.raw_data)

        # êµ­ì ê³¼ ëª©ì ì—ì„œ í‚¤ì›Œë“œ ì œê±°
        for keyword in keywords_to_remove:
            # êµ­ì ì—ì„œ í‚¤ì›Œë“œ í¬í•¨ëœ í–‰ ì œê±°
            mask_nationality = ~self.raw_data["êµ­ì "].str.contains(keyword, na=False, case=False)
            # ëª©ì ì—ì„œ í‚¤ì›Œë“œ í¬í•¨ëœ í–‰ ì œê±°
            mask_purpose = ~self.raw_data["ëª©ì "].str.contains(keyword, na=False, case=False)

            # ë‘ ì¡°ê±´ ëª¨ë‘ ë§Œì¡±í•˜ëŠ” í–‰ë§Œ ìœ ì§€
            self.raw_data = self.raw_data[mask_nationality & mask_purpose]

        # "ê³„"ë§Œ ìžˆëŠ” í–‰ ì œê±° (ì •í™•ížˆ "ê³„"ì¸ ê²½ìš°)
        self.raw_data = self.raw_data[
            (self.raw_data["êµ­ì "].str.strip() != "ê³„")
            & (self.raw_data["ëª©ì "].str.strip() != "ê³„")
        ]

        # ë¹ˆ ê°’ì´ë‚˜ ê³µë°±ë§Œ ìžˆëŠ” í–‰ ì œê±°
        self.raw_data = self.raw_data[
            (self.raw_data["êµ­ì "].str.strip() != "") & (self.raw_data["ëª©ì "].str.strip() != "")
        ]

        removed_count = original_count - len(self.raw_data)
        print(f"âœ… {removed_count}ê°œ í–‰ ì œê±° ì™„ë£Œ (ìž”ì—¬: {len(self.raw_data)}í–‰)")

    def reshape_to_long_format(self):
        """
        Wide formatì„ Long formatìœ¼ë¡œ ë³€í™˜
        """
        print("\nðŸ”„ Long formatìœ¼ë¡œ ë³€í™˜ ì¤‘...")

        # êµ­ì , ëª©ì  ì»¬ëŸ¼ì„ ì œì™¸í•œ ë‚˜ë¨¸ì§€ê°€ ë‚ ì§œ ì»¬ëŸ¼
        date_columns = [col for col in self.raw_data.columns if col not in ["êµ­ì ", "ëª©ì "]]

        # Wide to Long ë³€í™˜
        long_data = pd.melt(
            self.raw_data,
            id_vars=["êµ­ì ", "ëª©ì "],
            value_vars=date_columns,
            var_name="ì—°ì›”",
            value_name="ìž…êµ­ìžìˆ˜",
        )

        # ì‰¼í‘œê°€ í¬í•¨ëœ ìˆ«ìž ì²˜ë¦¬
        long_data["ìž…êµ­ìžìˆ˜"] = (
            long_data["ìž…êµ­ìžìˆ˜"].astype(str).str.replace(",", "").str.replace('"', "")
        )

        # ìˆ«ìžê°€ ì•„ë‹Œ ê°’ë“¤ ì œê±°
        long_data = long_data[long_data["ìž…êµ­ìžìˆ˜"].str.isnumeric()]
        long_data["ìž…êµ­ìžìˆ˜"] = pd.to_numeric(long_data["ìž…êµ­ìžìˆ˜"])

        # ì—°ì›” ì •ë¦¬ (ì˜ˆ: "2005ë…„01ì›”" -> "2005-01")
        long_data["ì—°ì›”"] = long_data["ì—°ì›”"].str.replace("ë…„", "-").str.replace("ì›”", "")

        # "ê³„" ê°’ì´ í¬í•¨ëœ ì—°ì›” ë°ì´í„° ì œê±°
        long_data = long_data[~long_data["ì—°ì›”"].str.contains("ê³„", na=False)]

        # ì—°ì›”ì´ ì˜¬ë°”ë¥¸ ë‚ ì§œ í˜•ì‹ì¸ì§€ í™•ì¸ (YYYY-MM í˜•íƒœ)
        import re

        date_pattern = r"^\d{4}-\d{2}$"
        long_data = long_data[long_data["ì—°ì›”"].str.match(date_pattern, na=False)]

        self.processed_data = long_data
        print(f"âœ… Long format ë³€í™˜ ì™„ë£Œ: {len(self.processed_data)}í–‰")

    def add_date_features(self):
        """
        ë‚ ì§œ ê´€ë ¨ íŠ¹ì„± ë³€ìˆ˜ ì¶”ê°€
        """
        print("\nðŸ“… ë‚ ì§œ íŠ¹ì„± ë³€ìˆ˜ ìƒì„± ì¤‘...")

        # ì—°ì›”ì„ ë‚ ì§œë¡œ ë³€í™˜ (ì˜ˆ: 2015-01 -> 2015-01-01)
        try:
            self.processed_data["ë‚ ì§œ"] = pd.to_datetime(
                self.processed_data["ì—°ì›”"] + "-01", format="%Y-%m-%d"
            )
        except:
            # ë‹¤ë¥¸ í˜•ì‹ ì‹œë„
            self.processed_data["ë‚ ì§œ"] = pd.to_datetime(
                self.processed_data["ì—°ì›”"], infer_datetime_format=True
            )

        # ì—°ë„, ì›”, ë¶„ê¸°, ê³„ì ˆ ì¶”ê°€
        self.processed_data["ì—°ë„"] = self.processed_data["ë‚ ì§œ"].dt.year
        self.processed_data["ì›”"] = self.processed_data["ë‚ ì§œ"].dt.month
        self.processed_data["ë¶„ê¸°"] = self.processed_data["ë‚ ì§œ"].dt.quarter

        # ê³„ì ˆ ì •ì˜ (3-5ì›”: ë´„, 6-8ì›”: ì—¬ë¦„, 9-11ì›”: ê°€ì„, 12-2ì›”: ê²¨ìš¸)
        season_map = {
            12: "ê²¨ìš¸",
            1: "ê²¨ìš¸",
            2: "ê²¨ìš¸",
            3: "ë´„",
            4: "ë´„",
            5: "ë´„",
            6: "ì—¬ë¦„",
            7: "ì—¬ë¦„",
            8: "ì—¬ë¦„",
            9: "ê°€ì„",
            10: "ê°€ì„",
            11: "ê°€ì„",
        }
        self.processed_data["ê³„ì ˆ"] = self.processed_data["ì›”"].map(season_map)

        # ì½”ë¡œë‚˜ ì‹œê¸° êµ¬ë¶„ (2020ë…„ 3ì›” ~ 2022ë…„ 6ì›”)
        covid_start = pd.to_datetime("2020-03-01")
        covid_end = pd.to_datetime("2022-06-30")
        self.processed_data["ì½”ë¡œë‚˜ê¸°ê°„"] = (
            (self.processed_data["ë‚ ì§œ"] >= covid_start)
            & (self.processed_data["ë‚ ì§œ"] <= covid_end)
        ).astype(int)

        # ì‹œê³„ì—´ ìˆœì„œ (ë”¥ëŸ¬ë‹ ëª¨ë¸ìš©)
        self.processed_data = self.processed_data.sort_values(["êµ­ì ", "ëª©ì ", "ë‚ ì§œ"])
        self.processed_data["ì‹œê³„ì—´ìˆœì„œ"] = (
            self.processed_data.groupby(["êµ­ì ", "ëª©ì "]).cumcount() + 1
        )

        print("âœ… ë‚ ì§œ íŠ¹ì„± ë³€ìˆ˜ ìƒì„± ì™„ë£Œ")

    def add_lag_features(self):
        """
        ì§€ì—° íŠ¹ì„± ë³€ìˆ˜ ì¶”ê°€ (ë”¥ëŸ¬ë‹ ëª¨ë¸ìš©)
        """
        print("\nâ° ì§€ì—° íŠ¹ì„± ë³€ìˆ˜ ìƒì„± ì¤‘...")

        # êµ­ì -ëª©ì ë³„ë¡œ ê·¸ë£¹í™”
        grouped = self.processed_data.groupby(["êµ­ì ", "ëª©ì "])

        # ê° ê·¸ë£¹ë³„ë¡œ ì§€ì—° ë³€ìˆ˜ ìƒì„±
        lag_features = []

        for name, group in grouped:
            group = group.sort_values("ë‚ ì§œ").copy()

            # 1ê°œì›”ì „, 3ê°œì›”ì „, 12ê°œì›”ì „ ìž…êµ­ìžìˆ˜
            group["ìž…êµ­ìžìˆ˜_1ê°œì›”ì „"] = group["ìž…êµ­ìžìˆ˜"].shift(1)
            group["ìž…êµ­ìžìˆ˜_3ê°œì›”ì „"] = group["ìž…êµ­ìžìˆ˜"].shift(3)
            group["ìž…êµ­ìžìˆ˜_12ê°œì›”ì „"] = group["ìž…êµ­ìžìˆ˜"].shift(12)

            # ì´ë™í‰ê·  (3ê°œì›”, 12ê°œì›”)
            group["ìž…êµ­ìžìˆ˜_3ê°œì›”í‰ê· "] = group["ìž…êµ­ìžìˆ˜"].rolling(window=3, min_periods=1).mean()
            group["ìž…êµ­ìžìˆ˜_12ê°œì›”í‰ê· "] = (
                group["ìž…êµ­ìžìˆ˜"].rolling(window=12, min_periods=1).mean()
            )

            # ì „ë…„ë™ì›”ëŒ€ë¹„ ì¦ê°ë¥ 
            group["ì „ë…„ë™ì›”ëŒ€ë¹„ì¦ê°ë¥ "] = (
                (group["ìž…êµ­ìžìˆ˜"] - group["ìž…êµ­ìžìˆ˜_12ê°œì›”ì „"]) / group["ìž…êµ­ìžìˆ˜_12ê°œì›”ì „"] * 100
            ).fillna(0)

            lag_features.append(group)

        # ëª¨ë“  ê·¸ë£¹ í•©ì¹˜ê¸°
        self.processed_data = pd.concat(lag_features, ignore_index=True)

        print("âœ… ì§€ì—° íŠ¹ì„± ë³€ìˆ˜ ìƒì„± ì™„ë£Œ")

    def save_processed_data(self):
        """
        ì „ì²˜ë¦¬ëœ ë°ì´í„° ì €ìž¥
        """
        print("\nðŸ’¾ ì „ì²˜ë¦¬ ë°ì´í„° ì €ìž¥ ì¤‘...")

        # íŒŒì¼ëª… ìƒì„±
        output_file = os.path.join(self.output_dir, "ì™¸êµ­ì¸ìž…êµ­ìž_ì „ì²˜ë¦¬ì™„ë£Œ_ë”¥ëŸ¬ë‹ìš©.csv")

        # ì»¬ëŸ¼ ìˆœì„œ ì •ë¦¬ (ë‚ ì§œ, ì—°ì›” ì»¬ëŸ¼ ì œê±°)
        column_order = [
            "êµ­ì ",
            "ëª©ì ",
            "ì—°ë„",
            "ì›”",
            "ë¶„ê¸°",
            "ê³„ì ˆ",
            "ì½”ë¡œë‚˜ê¸°ê°„",
            "ì‹œê³„ì—´ìˆœì„œ",
            "ìž…êµ­ìžìˆ˜",
            "ìž…êµ­ìžìˆ˜_1ê°œì›”ì „",
            "ìž…êµ­ìžìˆ˜_3ê°œì›”ì „",
            "ìž…êµ­ìžìˆ˜_12ê°œì›”ì „",
            "ìž…êµ­ìžìˆ˜_3ê°œì›”í‰ê· ",
            "ìž…êµ­ìžìˆ˜_12ê°œì›”í‰ê· ",
            "ì „ë…„ë™ì›”ëŒ€ë¹„ì¦ê°ë¥ ",
        ]

        # ì¡´ìž¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ ì„ íƒ
        available_columns = [col for col in column_order if col in self.processed_data.columns]
        final_data = self.processed_data[available_columns]

        # CSV ì €ìž¥
        final_data.to_csv(output_file, index=False, encoding="utf-8-sig")

        print(f"âœ… ì €ìž¥ ì™„ë£Œ: {output_file}")
        print(f"ðŸ“Š ìµœì¢… ë°ì´í„° í˜•íƒœ: {final_data.shape[0]}í–‰ Ã— {final_data.shape[1]}ì—´")

        # ìƒ˜í”Œ ë°ì´í„° ì¶œë ¥
        print(f"\nðŸ“‹ **ìµœì¢… ì „ì²˜ë¦¬ ë°ì´í„° ìƒ˜í”Œ:**")
        print(final_data.head(10).to_string())

        return output_file

    def get_data_summary(self):
        """
        ë°ì´í„° ìš”ì•½ ì •ë³´ ì¶œë ¥
        """
        if self.processed_data is not None:
            print(f"\nðŸ“ˆ **ë°ì´í„° ìš”ì•½ ì •ë³´**")
            print(f"- ì´ ë°ì´í„° í–‰ìˆ˜: {len(self.processed_data):,}")
            print(f"- êµ­ì  ìˆ˜: {self.processed_data['êµ­ì '].nunique()}")
            print(f"- ëª©ì  ìˆ˜: {self.processed_data['ëª©ì '].nunique()}")
            print(
                f"- ë‚ ì§œ ë²”ìœ„: {self.processed_data['ë‚ ì§œ'].min()} ~ {self.processed_data['ë‚ ì§œ'].max()}"
            )
            print(f"- ì½”ë¡œë‚˜ ê¸°ê°„ ë°ì´í„°: {(self.processed_data['ì½”ë¡œë‚˜ê¸°ê°„'] == 1).sum():,}í–‰")
            print(f"- ë¹„ì½”ë¡œë‚˜ ê¸°ê°„ ë°ì´í„°: {(self.processed_data['ì½”ë¡œë‚˜ê¸°ê°„'] == 0).sum():,}í–‰")

            print(f"\nðŸ·ï¸ **êµ­ì  ëª©ë¡ (ìƒìœ„ 10ê°œ):**")
            print(self.processed_data["êµ­ì "].value_counts().head(10))

            print(f"\nðŸŽ¯ **ëª©ì  ëª©ë¡:**")
            print(self.processed_data["ëª©ì "].value_counts())

    def run_preprocessing(self):
        """
        ì „ì²´ ì „ì²˜ë¦¬ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰

        Returns:
            bool: ì „ì²˜ë¦¬ ì„±ê³µ ì—¬ë¶€
        """
        try:
            print("=" * 60)
            print("ðŸš€ ì™¸êµ­ì¸ ìž…êµ­ìž ë°ì´í„° ì „ì²˜ë¦¬ ì‹œìž‘ (ì½”ë¡œë‚˜ ì‹œê¸° í¬í•¨)")
            print("=" * 60)

            # 1. ë°ì´í„° ë¡œë“œ
            if not self.load_data():
                return False

            # 2. ë°ì´í„° í´ë¦¬ë‹
            self.clean_data()

            # 3. ì†Œê³„/í•©ê³„ ì œê±°
            self.remove_aggregated_rows()

            # 4. Long format ë³€í™˜
            self.reshape_to_long_format()

            # 5. ë‚ ì§œ íŠ¹ì„± ì¶”ê°€
            self.add_date_features()

            # 6. ì§€ì—° íŠ¹ì„± ì¶”ê°€
            self.add_lag_features()

            # 7. ë°ì´í„° ì €ìž¥
            output_file = self.save_processed_data()

            # 8. ìš”ì•½ ì •ë³´ ì¶œë ¥
            self.get_data_summary()

            print("\n" + "=" * 60)
            print("âœ… ì „ì²˜ë¦¬ ì™„ë£Œ! ðŸŽ‰")
            print("=" * 60)

            return True

        except Exception as e:
            print(f"\nâŒ ì „ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            import traceback

            traceback.print_exc()
            return False


# ì‹¤í–‰ ë¶€ë¶„
if __name__ == "__main__":
    # ë°ì´í„° ì „ì²˜ë¦¬ ì‹¤í–‰
    processor = ForeignVisitorDataProcessor()
    success = processor.run_preprocessing()

    if success:
        print(f"\nðŸŽ¯ **ë‹¤ìŒ ë‹¨ê³„:** ìƒì„±ëœ CSV íŒŒì¼ë¡œ ë”¥ëŸ¬ë‹ ëª¨ë¸ í•™ìŠµì„ ì§„í–‰í•˜ì„¸ìš”!")
    else:
        print(f"\nâš ï¸ ì „ì²˜ë¦¬ ì‹¤íŒ¨. ì˜¤ë¥˜ë¥¼ í™•ì¸í•˜ê³  ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
