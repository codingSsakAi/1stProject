# -*- coding: utf-8 -*-
"""
ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬ í´ë˜ìŠ¤
Author: Jin
Created: 2025-01-15
"""

import pandas as pd
import numpy as np
from typing import Tuple, Dict, Any
import logging
import sys
import os

# í”„ë¡œì íŠ¸ ê²½ë¡œë¥¼ sys.pathì— ì¶”ê°€
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.append(project_root)

from config.config import *
from scripts.utils import *

logger = logging.getLogger(__name__)


class DataLoader:
    """ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬ í´ë˜ìŠ¤"""

    def __init__(self, data_file: str = DATA_FILE):
        """
        ì´ˆê¸°í™”

        Args:
            data_file: ë°ì´í„° íŒŒì¼ ê²½ë¡œ
        """
        self.data_file = data_file
        self.raw_data = None
        self.processed_data = None
        self.encoders = {}
        self.scaler = None

        logger.info(f"ğŸ“‚ ë°ì´í„° ë¡œë” ì´ˆê¸°í™”: {data_file}")

    def load_data(self) -> pd.DataFrame:
        """ë°ì´í„° ë¡œë“œ"""
        try:
            self.raw_data = pd.read_csv(self.data_file, encoding="utf-8-sig")
            logger.info(
                f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {self.raw_data.shape[0]}í–‰ Ã— {self.raw_data.shape[1]}ì—´"
            )
            return self.raw_data
        except Exception as e:
            logger.error(f"âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            raise

    def preprocess_data(self) -> pd.DataFrame:
        """ë°ì´í„° ì „ì²˜ë¦¬"""
        if self.raw_data is None:
            self.load_data()

        df = self.raw_data.copy()

        # ê²°ì¸¡ê°’ ì²˜ë¦¬
        logger.info("ğŸ”„ ê²°ì¸¡ê°’ ì²˜ë¦¬ ì¤‘...")
        df = df.fillna(0)

        # ì¹´í…Œê³ ë¦¬ ì¸ì½”ë”©
        logger.info("ğŸ”„ ì¹´í…Œê³ ë¦¬ ì¸ì½”ë”© ì¤‘...")
        df, self.encoders = encode_categorical_features(df)

        # ë‚ ì§œ ì»¬ëŸ¼ ì¶”ê°€ (í•„ìš”ì‹œ)
        if "ë‚ ì§œ" not in df.columns:
            df["ë‚ ì§œ"] = pd.to_datetime(
                df["ì—°ë„"].astype(str) + "-" + df["ì›”"].astype(str).str.zfill(2) + "-01"
            )

        # ğŸ”§ ë¬´í•œëŒ€ ê°’ ë° ì´ìƒì¹˜ ì²˜ë¦¬ ì¶”ê°€
        logger.info("ğŸ”„ ë¬´í•œëŒ€ ê°’ ë° ì´ìƒì¹˜ ì²˜ë¦¬ ì¤‘...")

        # ë¬´í•œëŒ€ ê°’ì„ 0ìœ¼ë¡œ ë³€ê²½
        df = df.replace([np.inf, -np.inf], 0)

        # NaN ê°’ ì¬í™•ì¸ ë° ì²˜ë¦¬
        df = df.fillna(0)

        # íƒ€ê²Ÿ ì»¬ëŸ¼ ì´ìƒì¹˜ ì²˜ë¦¬ (99.9% ë¶„ìœ„ìˆ˜ ì´ìƒ ê°’ì„ ìºí•‘)
        if TARGET_COLUMN in df.columns:
            upper_limit = df[TARGET_COLUMN].quantile(0.999)
            original_max = df[TARGET_COLUMN].max()
            df[TARGET_COLUMN] = np.clip(df[TARGET_COLUMN], 0, upper_limit)
            logger.info(
                f"   - íƒ€ê²Ÿ ì»¬ëŸ¼ ì´ìƒì¹˜ ì²˜ë¦¬: ìµœëŒ€ê°’ {original_max:.0f} â†’ {upper_limit:.0f}"
            )

        # ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ë“¤ì˜ ì´ìƒì¹˜ ì²˜ë¦¬
        numeric_columns = df.select_dtypes(include=[np.number]).columns
        for col in numeric_columns:
            if col != TARGET_COLUMN:  # íƒ€ê²Ÿ ì»¬ëŸ¼ì€ ì´ë¯¸ ì²˜ë¦¬í–ˆìœ¼ë¯€ë¡œ ì œì™¸
                # ê·¹ê°’ ì œê±° (99.9% ë¶„ìœ„ìˆ˜ ê¸°ì¤€)
                upper_limit = df[col].quantile(0.999)
                if upper_limit > 0:
                    df[col] = np.clip(df[col], 0, upper_limit)

        # ëª¨ë“  ìˆ˜ì¹˜í˜• ë°ì´í„°ê°€ ìœ í•œí•œì§€ í™•ì¸
        for col in numeric_columns:
            if not np.isfinite(df[col]).all():
                logger.warning(f"âš ï¸ {col} ì»¬ëŸ¼ì— ì—¬ì „íˆ ë¬´í•œëŒ€ ê°’ì´ ìˆìŠµë‹ˆë‹¤. 0ìœ¼ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")
                df[col] = df[col].replace([np.inf, -np.inf], 0)
                df[col] = df[col].fillna(0)

        # ì •ë ¬
        df = df.sort_values(["êµ­ì ", "ëª©ì ", "ì—°ë„", "ì›”"]).reset_index(drop=True)

        self.processed_data = df
        logger.info(f"âœ… ë°ì´í„° ì „ì²˜ë¦¬ ì™„ë£Œ: {df.shape[0]}í–‰ Ã— {df.shape[1]}ì—´")

        return df

    def split_data(
        self,
        train_end_year: int = TRAIN_END_YEAR,
        val_end_year: int = VAL_END_YEAR,
        test_start_year: int = TEST_START_YEAR,
    ) -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:
        """ë°ì´í„° ë¶„í• """
        if self.processed_data is None:
            self.preprocess_data()

        df = self.processed_data.copy()

        # ì‹œê°„ ê¸°ë°˜ ë¶„í• 
        train_data = df[df["ì—°ë„"] <= train_end_year]
        val_data = df[(df["ì—°ë„"] > train_end_year) & (df["ì—°ë„"] <= val_end_year)]
        test_data = df[df["ì—°ë„"] >= test_start_year]

        logger.info(f"ğŸ“Š ë°ì´í„° ë¶„í•  ì™„ë£Œ:")
        logger.info(
            f"   - í•™ìŠµ ë°ì´í„°: {len(train_data)}í–‰ ({train_data['ì—°ë„'].min()}-{train_data['ì—°ë„'].max()})"
        )
        logger.info(
            f"   - ê²€ì¦ ë°ì´í„°: {len(val_data)}í–‰ ({val_data['ì—°ë„'].min()}-{val_data['ì—°ë„'].max()})"
        )
        logger.info(
            f"   - í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(test_data)}í–‰ ({test_data['ì—°ë„'].min()}-{test_data['ì—°ë„'].max()})"
        )

        return train_data, val_data, test_data

    def prepare_lstm_dataset(
        self, sequence_length: int = SEQUENCE_LENGTH
    ) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray]:
        """LSTMìš© ë°ì´í„°ì…‹ ì¤€ë¹„"""
        train_data, val_data, test_data = self.split_data()

        logger.info("ğŸ”„ LSTM ë°ì´í„°ì…‹ ì¤€ë¹„ ì¤‘...")

        # ì‹œí€€ìŠ¤ ë°ì´í„° ìƒì„±
        X_train, y_train = prepare_lstm_data(train_data, sequence_length)
        X_val, y_val = prepare_lstm_data(val_data, sequence_length)
        X_test, y_test = prepare_lstm_data(test_data, sequence_length)

        logger.info(f"ğŸ“Š LSTM ë°ì´í„°ì…‹ í¬ê¸°:")
        logger.info(f"   - í•™ìŠµ: X{X_train.shape}, y{y_train.shape}")
        logger.info(f"   - ê²€ì¦: X{X_val.shape}, y{y_val.shape}")
        logger.info(f"   - í…ŒìŠ¤íŠ¸: X{X_test.shape}, y{y_test.shape}")

        return X_train, y_train, X_val, y_val, X_test, y_test

    def get_data_summary(self) -> Dict[str, Any]:
        """ë°ì´í„° ìš”ì•½ ì •ë³´"""
        if self.processed_data is None:
            self.preprocess_data()

        df = self.processed_data

        summary = {
            "total_rows": len(df),
            "total_columns": len(df.columns),
            "date_range": f"{df['ì—°ë„'].min()}-{df['ì—°ë„'].max()}",
            "unique_countries": df["êµ­ì "].nunique(),
            "unique_purposes": df["ëª©ì "].nunique(),
            "target_stats": {
                "mean": df[TARGET_COLUMN].mean(),
                "std": df[TARGET_COLUMN].std(),
                "min": df[TARGET_COLUMN].min(),
                "max": df[TARGET_COLUMN].max(),
                "median": df[TARGET_COLUMN].median(),
            },
            "missing_values": df.isnull().sum().to_dict(),
            "covid_period_ratio": df["ì½”ë¡œë‚˜ê¸°ê°„"].mean(),
        }

        return summary

    def print_data_info(self):
        """ë°ì´í„° ì •ë³´ ì¶œë ¥"""
        summary = self.get_data_summary()

        print(f"\nğŸ“ˆ **ë°ì´í„° ìš”ì•½ ì •ë³´**")
        print(f"- ì´ í–‰ìˆ˜: {summary['total_rows']:,}")
        print(f"- ì´ ì»¬ëŸ¼ìˆ˜: {summary['total_columns']}")
        print(f"- ë‚ ì§œ ë²”ìœ„: {summary['date_range']}")
        print(f"- êµ­ì  ìˆ˜: {summary['unique_countries']}")
        print(f"- ëª©ì  ìˆ˜: {summary['unique_purposes']}")
        print(f"- ì½”ë¡œë‚˜ ê¸°ê°„ ë¹„ìœ¨: {summary['covid_period_ratio']:.2%}")

        print(f"\nğŸ“Š **íƒ€ê²Ÿ ë³€ìˆ˜ ({TARGET_COLUMN}) í†µê³„**")
        stats = summary["target_stats"]
        print(f"- í‰ê· : {stats['mean']:.2f}")
        print(f"- í‘œì¤€í¸ì°¨: {stats['std']:.2f}")
        print(f"- ìµœì†Œê°’: {stats['min']:.2f}")
        print(f"- ìµœëŒ€ê°’: {stats['max']:.2f}")
        print(f"- ì¤‘ê°„ê°’: {stats['median']:.2f}")


# ì‹¤í–‰ ì˜ˆì‹œ
if __name__ == "__main__":
    # ë°ì´í„° ë¡œë” ìƒì„±
    loader = DataLoader()

    # ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
    data = loader.preprocess_data()

    # ë°ì´í„° ì •ë³´ ì¶œë ¥
    loader.print_data_info()

    # LSTM ë°ì´í„°ì…‹ ì¤€ë¹„
    X_train, y_train, X_val, y_val, X_test, y_test = loader.prepare_lstm_dataset()

    logger.info("âœ… ë°ì´í„° ë¡œë” í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
