# -*- coding: utf-8 -*-
"""
ì˜ˆì¸¡ ì‹¤í–‰ê¸° í´ë˜ìŠ¤
Author: Jin
Created: 2025-01-15
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import logging
import sys
import os
from typing import Dict, List, Any, Optional, Tuple
import warnings
from datetime import datetime, timedelta
import json
from pathlib import Path
import joblib

# í”„ë¡œì íŠ¸ ê²½ë¡œë¥¼ sys.pathì— ì¶”ê°€
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.append(project_root)

from config.config import *
from scripts.utils import *
from scripts.data_loader import DataLoader
from scripts.lstm_model import LSTMModel

# í•œê¸€ í°íŠ¸ ì„¤ì •
setup_plotting()

warnings.filterwarnings("ignore")
logger = logging.getLogger(__name__)


class Predictor:
    """ì˜ˆì¸¡ ì‹¤í–‰ê¸° í´ë˜ìŠ¤"""

    def __init__(self, data_loader: DataLoader = None):
        """
        ì´ˆê¸°í™”

        Args:
            data_loader: ë°ì´í„° ë¡œë” ì¸ìŠ¤í„´ìŠ¤
        """
        self.data_loader = data_loader or DataLoader()
        self.models = {}
        self.predictions = {}
        self.ensemble_predictions = {}
        self.feature_scalers = {}
        self.target_scalers = {}

        logger.info("ğŸ”® ì˜ˆì¸¡ ì‹¤í–‰ê¸° ì´ˆê¸°í™”")

    def load_model(self, model_name: str, model_path: str, model_class):
        """
        ëª¨ë¸ ë¡œë“œ

        Args:
            model_name: ëª¨ë¸ ì´ë¦„
            model_path: ëª¨ë¸ íŒŒì¼ ê²½ë¡œ
            model_class: ëª¨ë¸ í´ë˜ìŠ¤
        """
        try:
            model_instance = model_class()
            model_instance.load_model(model_path)

            self.models[model_name] = model_instance
            logger.info(f"âœ… {model_name} ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")

            # ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ ì‹œë„
            scaler_path = Path(model_path).parent / f"{model_name.lower()}_scalers.pkl"
            if scaler_path.exists():
                scalers = joblib.load(scaler_path)
                self.feature_scalers[model_name] = scalers.get("feature_scaler")
                self.target_scalers[model_name] = scalers.get("target_scaler")
                logger.info(f"âœ… {model_name} ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ ì™„ë£Œ")

        except Exception as e:
            logger.error(f"âŒ {model_name} ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            raise

    def prepare_prediction_data(
        self, data: pd.DataFrame, model_name: str, sequence_length: int = 12
    ) -> Tuple[np.ndarray, pd.DataFrame]:
        """
        ì˜ˆì¸¡ìš© ë°ì´í„° ì¤€ë¹„

        Args:
            data: ì…ë ¥ ë°ì´í„°
            model_name: ëª¨ë¸ ì´ë¦„
            sequence_length: ì‹œí€€ìŠ¤ ê¸¸ì´

        Returns:
            ì¤€ë¹„ëœ ì˜ˆì¸¡ìš© ë°ì´í„°ì™€ ë©”íƒ€ë°ì´í„°
        """
        logger.info(f"ğŸ“Š {model_name} ì˜ˆì¸¡ìš© ë°ì´í„° ì¤€ë¹„ ì¤‘...")

        # ë°ì´í„° ë³µì‚¬
        df = data.copy()

        # íŠ¹ì„± ì»¬ëŸ¼ ì •ì˜
        feature_columns = [
            col for col in df.columns if col not in ["ë‚ ì§œ", "êµ­ì ", "ëª©ì ", "ì…êµ­ììˆ˜"]
        ]

        # íŠ¹ì„± ë°ì´í„° ì¶”ì¶œ
        X = df[feature_columns].values

        # ìŠ¤ì¼€ì¼ë§ (ìˆì„ ê²½ìš°)
        if model_name in self.feature_scalers and self.feature_scalers[model_name] is not None:
            X = self.feature_scalers[model_name].transform(X)

        # ì‹œí€€ìŠ¤ ë°ì´í„° ìƒì„± (LSTMìš©)
        if len(X) >= sequence_length:
            X_seq = []
            metadata = []

            for i in range(sequence_length, len(X) + 1):
                X_seq.append(X[i - sequence_length : i])
                metadata.append(
                    {
                        "index": i - 1,
                        "date": df.iloc[i - 1]["ë‚ ì§œ"] if "ë‚ ì§œ" in df.columns else None,
                        "nationality": df.iloc[i - 1]["êµ­ì "] if "êµ­ì " in df.columns else None,
                        "purpose": df.iloc[i - 1]["ëª©ì "] if "ëª©ì " in df.columns else None,
                    }
                )

            X_seq = np.array(X_seq)
            metadata_df = pd.DataFrame(metadata)

            logger.info(f"âœ… ì‹œí€€ìŠ¤ ë°ì´í„° ìƒì„± ì™„ë£Œ: {X_seq.shape}")

            return X_seq, metadata_df
        else:
            logger.warning(f"âš ï¸ ë°ì´í„° ê¸¸ì´ ë¶€ì¡±: {len(X)} < {sequence_length}")
            return None, None

    def predict_single_model(
        self, model_name: str, X: np.ndarray, return_confidence: bool = False
    ) -> Dict[str, Any]:
        """
        ë‹¨ì¼ ëª¨ë¸ ì˜ˆì¸¡

        Args:
            model_name: ëª¨ë¸ ì´ë¦„
            X: ì…ë ¥ ë°ì´í„°
            return_confidence: ì‹ ë¢°êµ¬ê°„ ë°˜í™˜ ì—¬ë¶€

        Returns:
            ì˜ˆì¸¡ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        if model_name not in self.models:
            raise ValueError(f"ë¡œë“œë˜ì§€ ì•Šì€ ëª¨ë¸: {model_name}")

        logger.info(f"ğŸ”® {model_name} ì˜ˆì¸¡ ìˆ˜í–‰ ì¤‘...")

        model = self.models[model_name]

        # ì˜ˆì¸¡ ìˆ˜í–‰
        predictions = model.predict(X)

        # ì—­ìŠ¤ì¼€ì¼ë§ (ìˆì„ ê²½ìš°)
        if model_name in self.target_scalers and self.target_scalers[model_name] is not None:
            predictions = (
                self.target_scalers[model_name]
                .inverse_transform(predictions.reshape(-1, 1))
                .flatten()
            )

        result = {
            "model_name": model_name,
            "predictions": predictions,
            "num_predictions": len(predictions),
        }

        # ì‹ ë¢°êµ¬ê°„ ê³„ì‚° (ëª¬í…Œì¹´ë¥¼ë¡œ ë“œë¡­ì•„ì›ƒ)
        if return_confidence and hasattr(model, "predict_with_uncertainty"):
            try:
                mean_pred, std_pred = model.predict_with_uncertainty(X)

                # ì—­ìŠ¤ì¼€ì¼ë§
                if (
                    model_name in self.target_scalers
                    and self.target_scalers[model_name] is not None
                ):
                    mean_pred = (
                        self.target_scalers[model_name]
                        .inverse_transform(mean_pred.reshape(-1, 1))
                        .flatten()
                    )
                    # í‘œì¤€í¸ì°¨ëŠ” ìŠ¤ì¼€ì¼ë§Œ ì¡°ì •
                    scale = self.target_scalers[model_name].scale_[0]
                    std_pred = std_pred * scale

                result["confidence"] = {
                    "mean": mean_pred,
                    "std": std_pred,
                    "upper_95": mean_pred + 1.96 * std_pred,
                    "lower_95": mean_pred - 1.96 * std_pred,
                    "upper_68": mean_pred + std_pred,
                    "lower_68": mean_pred - std_pred,
                }
            except Exception as e:
                logger.warning(f"ì‹ ë¢°êµ¬ê°„ ê³„ì‚° ì‹¤íŒ¨: {str(e)}")

        self.predictions[model_name] = result

        logger.info(f"âœ… {model_name} ì˜ˆì¸¡ ì™„ë£Œ: {len(predictions)}ê°œ")

        return result

    def predict_ensemble(
        self,
        model_names: List[str],
        X: np.ndarray,
        weights: List[float] = None,
        method: str = "weighted_average",
    ) -> Dict[str, Any]:
        """
        ì•™ìƒë¸” ì˜ˆì¸¡

        Args:
            model_names: ì‚¬ìš©í•  ëª¨ë¸ ì´ë¦„ ë¦¬ìŠ¤íŠ¸
            X: ì…ë ¥ ë°ì´í„°
            weights: ëª¨ë¸ë³„ ê°€ì¤‘ì¹˜ (Noneì´ë©´ ê· ë“± ê°€ì¤‘ì¹˜)
            method: ì•™ìƒë¸” ë°©ë²• ('weighted_average', 'median', 'best_performance')

        Returns:
            ì•™ìƒë¸” ì˜ˆì¸¡ ê²°ê³¼
        """
        logger.info(f"ğŸ¯ ì•™ìƒë¸” ì˜ˆì¸¡ ìˆ˜í–‰: {model_names}")

        # ê°œë³„ ëª¨ë¸ ì˜ˆì¸¡
        individual_predictions = {}
        for model_name in model_names:
            if model_name in self.models:
                pred_result = self.predict_single_model(model_name, X)
                individual_predictions[model_name] = pred_result["predictions"]

        if not individual_predictions:
            raise ValueError("ìœ íš¨í•œ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")

        # ê°€ì¤‘ì¹˜ ì„¤ì •
        if weights is None:
            weights = [1.0 / len(individual_predictions)] * len(individual_predictions)
        elif len(weights) != len(individual_predictions):
            raise ValueError("ê°€ì¤‘ì¹˜ ê°œìˆ˜ê°€ ëª¨ë¸ ê°œìˆ˜ì™€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

        # ì•™ìƒë¸” ì˜ˆì¸¡ ìˆ˜í–‰
        predictions_array = np.array(list(individual_predictions.values()))

        if method == "weighted_average":
            ensemble_pred = np.average(predictions_array, axis=0, weights=weights)
        elif method == "median":
            ensemble_pred = np.median(predictions_array, axis=0)
        elif method == "best_performance":
            # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì„ íƒ (ê°€ì¤‘ì¹˜ ê¸°ë°˜)
            best_model_idx = np.argmax(weights)
            ensemble_pred = predictions_array[best_model_idx]
        else:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì•™ìƒë¸” ë°©ë²•: {method}")

        result = {
            "ensemble_method": method,
            "models_used": model_names,
            "weights": weights,
            "predictions": ensemble_pred,
            "individual_predictions": individual_predictions,
            "num_predictions": len(ensemble_pred),
        }

        # ì˜ˆì¸¡ ë¶„ì‚° ê³„ì‚°
        pred_variance = np.var(predictions_array, axis=0)
        pred_std = np.std(predictions_array, axis=0)

        result["uncertainty"] = {
            "variance": pred_variance,
            "std": pred_std,
            "upper_95": ensemble_pred + 1.96 * pred_std,
            "lower_95": ensemble_pred - 1.96 * pred_std,
        }

        self.ensemble_predictions[f"ensemble_{method}"] = result

        logger.info(f"âœ… ì•™ìƒë¸” ì˜ˆì¸¡ ì™„ë£Œ: {len(ensemble_pred)}ê°œ")

        return result

    def predict_future(
        self, model_name: str, steps: int = 12, use_recursive: bool = True
    ) -> Dict[str, Any]:
        """
        ë¯¸ë˜ ì˜ˆì¸¡

        Args:
            model_name: ì‚¬ìš©í•  ëª¨ë¸ ì´ë¦„
            steps: ì˜ˆì¸¡í•  ë¯¸ë˜ ë‹¨ê³„ ìˆ˜
            use_recursive: ì¬ê·€ì  ì˜ˆì¸¡ ì‚¬ìš© ì—¬ë¶€

        Returns:
            ë¯¸ë˜ ì˜ˆì¸¡ ê²°ê³¼
        """
        logger.info(f"ğŸ”® {model_name} ë¯¸ë˜ ì˜ˆì¸¡ ìˆ˜í–‰: {steps}ë‹¨ê³„")

        if model_name not in self.models:
            raise ValueError(f"ë¡œë“œë˜ì§€ ì•Šì€ ëª¨ë¸: {model_name}")

        # ìµœì‹  ë°ì´í„° ë¡œë“œ
        df = self.data_loader.load_data()

        # ì˜ˆì¸¡ìš© ë°ì´í„° ì¤€ë¹„
        X_seq, metadata = self.prepare_prediction_data(df, model_name)

        if X_seq is None:
            raise ValueError("ì˜ˆì¸¡ìš© ë°ì´í„° ì¤€ë¹„ ì‹¤íŒ¨")

        model = self.models[model_name]

        # ë§ˆì§€ë§‰ ì‹œí€€ìŠ¤ ê°€ì ¸ì˜¤ê¸°
        last_sequence = X_seq[-1:].copy()

        future_predictions = []
        prediction_dates = []

        # ê¸°ì¤€ ë‚ ì§œ ì„¤ì •
        last_date = pd.to_datetime(df["ë‚ ì§œ"].iloc[-1])

        for step in range(steps):
            # ì˜ˆì¸¡ ìˆ˜í–‰
            pred = model.predict(last_sequence)

            # ì—­ìŠ¤ì¼€ì¼ë§
            if model_name in self.target_scalers and self.target_scalers[model_name] is not None:
                pred_scaled = (
                    self.target_scalers[model_name].inverse_transform(pred.reshape(-1, 1)).flatten()
                )
            else:
                pred_scaled = pred.flatten()

            future_predictions.append(pred_scaled[0])

            # ë‹¤ìŒ ë‹¬ ê³„ì‚°
            next_date = last_date + timedelta(days=32)
            next_date = next_date.replace(day=1)  # ì›” ì²«ë‚ ë¡œ ì„¤ì •
            prediction_dates.append(next_date)
            last_date = next_date

            # ì¬ê·€ì  ì˜ˆì¸¡ì„ ìœ„í•œ ì‹œí€€ìŠ¤ ì—…ë°ì´íŠ¸
            if use_recursive and step < steps - 1:
                # ìƒˆë¡œìš´ íŠ¹ì„± ë²¡í„° ìƒì„± (ê°„ë‹¨í•œ ì˜ˆì‹œ)
                new_features = last_sequence[0, -1, :].copy()

                # ì…êµ­ììˆ˜ ê´€ë ¨ íŠ¹ì„±ë“¤ ì—…ë°ì´íŠ¸
                if len(new_features) > 0:
                    new_features[0] = pred[0]  # ì˜ˆì¸¡ê°’ìœ¼ë¡œ ì—…ë°ì´íŠ¸

                # ì‹œí€€ìŠ¤ ì—…ë°ì´íŠ¸
                last_sequence = np.roll(last_sequence, -1, axis=1)
                last_sequence[0, -1, :] = new_features

        result = {
            "model_name": model_name,
            "prediction_steps": steps,
            "recursive_prediction": use_recursive,
            "predictions": np.array(future_predictions),
            "prediction_dates": prediction_dates,
            "base_date": df["ë‚ ì§œ"].iloc[-1],
        }

        logger.info(f"âœ… {model_name} ë¯¸ë˜ ì˜ˆì¸¡ ì™„ë£Œ: {steps}ë‹¨ê³„")

        return result

    def plot_predictions(
        self, prediction_name: str, historical_data: pd.DataFrame = None, save_plots: bool = True
    ):
        """
        ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™”

        Args:
            prediction_name: ì˜ˆì¸¡ ê²°ê³¼ ì´ë¦„
            historical_data: ê³¼ê±° ë°ì´í„° (ë¹„êµìš©)
            save_plots: ê·¸ë˜í”„ ì €ì¥ ì—¬ë¶€
        """
        # ì˜ˆì¸¡ ê²°ê³¼ ì°¾ê¸°
        pred_result = None
        if prediction_name in self.predictions:
            pred_result = self.predictions[prediction_name]
        elif prediction_name in self.ensemble_predictions:
            pred_result = self.ensemble_predictions[prediction_name]

        if pred_result is None:
            logger.warning(f"ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {prediction_name}")
            return

        fig, axes = plt.subplots(2, 2, figsize=(15, 12))

        # 1. ì˜ˆì¸¡ ê²°ê³¼ ì‹œê³„ì—´
        predictions = pred_result["predictions"]

        if "prediction_dates" in pred_result:
            # ë¯¸ë˜ ì˜ˆì¸¡
            dates = pred_result["prediction_dates"]
            axes[0, 0].plot(dates, predictions, "b-", marker="o", label="ì˜ˆì¸¡ê°’")
            axes[0, 0].set_title(f"{prediction_name} - ë¯¸ë˜ ì˜ˆì¸¡")

            # ê³¼ê±° ë°ì´í„° ì¶”ê°€ (ìˆì„ ê²½ìš°)
            if historical_data is not None:
                hist_dates = pd.to_datetime(historical_data["ë‚ ì§œ"])
                hist_values = historical_data["ì…êµ­ììˆ˜"]
                axes[0, 0].plot(
                    hist_dates.tail(24), hist_values.tail(24), "g-", alpha=0.7, label="ê³¼ê±° ì‹¤ì œê°’"
                )
        else:
            # ì¼ë°˜ ì˜ˆì¸¡
            axes[0, 0].plot(predictions, "b-", marker="o", label="ì˜ˆì¸¡ê°’")
            axes[0, 0].set_title(f"{prediction_name} - ì˜ˆì¸¡ ê²°ê³¼")

        axes[0, 0].set_xlabel("ë‚ ì§œ")
        axes[0, 0].set_ylabel("ì…êµ­ììˆ˜")
        axes[0, 0].legend()
        axes[0, 0].grid(True, alpha=0.3)

        # 2. ì‹ ë¢°êµ¬ê°„ (ìˆì„ ê²½ìš°)
        if "confidence" in pred_result:
            conf = pred_result["confidence"]
            x_axis = range(len(predictions))

            axes[0, 1].plot(x_axis, conf["mean"], "b-", label="ì˜ˆì¸¡ í‰ê· ")
            axes[0, 1].fill_between(
                x_axis, conf["lower_95"], conf["upper_95"], alpha=0.3, label="95% ì‹ ë¢°êµ¬ê°„"
            )
            axes[0, 1].fill_between(
                x_axis, conf["lower_68"], conf["upper_68"], alpha=0.5, label="68% ì‹ ë¢°êµ¬ê°„"
            )
            axes[0, 1].set_title(f"{prediction_name} - ì‹ ë¢°êµ¬ê°„")
            axes[0, 1].legend()
            axes[0, 1].grid(True, alpha=0.3)
        elif "uncertainty" in pred_result:
            # ì•™ìƒë¸” ë¶ˆí™•ì‹¤ì„±
            unc = pred_result["uncertainty"]
            x_axis = range(len(predictions))

            axes[0, 1].plot(x_axis, predictions, "b-", label="ì•™ìƒë¸” ì˜ˆì¸¡")
            axes[0, 1].fill_between(
                x_axis, unc["lower_95"], unc["upper_95"], alpha=0.3, label="95% ë¶ˆí™•ì‹¤ì„±"
            )
            axes[0, 1].set_title(f"{prediction_name} - ë¶ˆí™•ì‹¤ì„±")
            axes[0, 1].legend()
            axes[0, 1].grid(True, alpha=0.3)

        # 3. ì˜ˆì¸¡ê°’ ë¶„í¬
        axes[1, 0].hist(predictions, bins=30, alpha=0.7, density=True)
        axes[1, 0].axvline(
            np.mean(predictions),
            color="red",
            linestyle="--",
            label=f"í‰ê· : {np.mean(predictions):.0f}",
        )
        axes[1, 0].set_title(f"{prediction_name} - ì˜ˆì¸¡ê°’ ë¶„í¬")
        axes[1, 0].set_xlabel("ì˜ˆì¸¡ê°’")
        axes[1, 0].set_ylabel("ë°€ë„")
        axes[1, 0].legend()
        axes[1, 0].grid(True, alpha=0.3)

        # 4. ê°œë³„ ëª¨ë¸ ë¹„êµ (ì•™ìƒë¸”ì¸ ê²½ìš°)
        if "individual_predictions" in pred_result:
            individual_preds = pred_result["individual_predictions"]
            x_axis = range(len(predictions))

            for model_name, model_preds in individual_preds.items():
                axes[1, 1].plot(x_axis, model_preds, alpha=0.7, label=model_name)

            axes[1, 1].plot(x_axis, predictions, "k-", linewidth=2, label="ì•™ìƒë¸”")
            axes[1, 1].set_title(f"{prediction_name} - ê°œë³„ ëª¨ë¸ ë¹„êµ")
            axes[1, 1].legend()
            axes[1, 1].grid(True, alpha=0.3)
        else:
            # ì˜ˆì¸¡ê°’ í†µê³„
            stats_text = f"""
ì˜ˆì¸¡ í†µê³„:
í‰ê· : {np.mean(predictions):.0f}
í‘œì¤€í¸ì°¨: {np.std(predictions):.0f}
ìµœì†Œê°’: {np.min(predictions):.0f}
ìµœëŒ€ê°’: {np.max(predictions):.0f}
ì¤‘ì•™ê°’: {np.median(predictions):.0f}
"""
            axes[1, 1].text(
                0.1,
                0.5,
                stats_text,
                transform=axes[1, 1].transAxes,
                fontsize=12,
                verticalalignment="center",
                bbox=dict(boxstyle="round,pad=0.3", facecolor="lightblue"),
            )
            axes[1, 1].set_title(f"{prediction_name} - ì˜ˆì¸¡ í†µê³„")
            axes[1, 1].axis("off")

        plt.tight_layout()

        if save_plots:
            safe_name = prediction_name.replace(" ", "_").lower()
            save_path = PLOTS_DIR / f"{safe_name}_predictions.png"
            plt.savefig(save_path, dpi=300, bbox_inches="tight")
            logger.info(f"ğŸ“Š ì˜ˆì¸¡ ê²°ê³¼ ê·¸ë˜í”„ ì €ì¥: {save_path}")

        plt.show()

    def save_predictions(self, prediction_name: str = None):
        """
        ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥

        Args:
            prediction_name: ì €ì¥í•  ì˜ˆì¸¡ ì´ë¦„ (Noneì´ë©´ ì „ì²´ ì €ì¥)
        """
        logger.info("ğŸ’¾ ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥ ì¤‘...")

        if prediction_name:
            # íŠ¹ì • ì˜ˆì¸¡ ê²°ê³¼ë§Œ ì €ì¥
            if prediction_name in self.predictions:
                self._save_single_prediction(prediction_name, self.predictions[prediction_name])
            elif prediction_name in self.ensemble_predictions:
                self._save_single_prediction(
                    prediction_name, self.ensemble_predictions[prediction_name]
                )
            else:
                logger.warning(f"ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {prediction_name}")
        else:
            # ëª¨ë“  ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥
            for name, result in self.predictions.items():
                self._save_single_prediction(name, result)

            for name, result in self.ensemble_predictions.items():
                self._save_single_prediction(name, result)

        logger.info("âœ… ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥ ì™„ë£Œ")

    def _save_single_prediction(self, name: str, result: Dict[str, Any]):
        """ë‹¨ì¼ ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥"""
        # CSV ì €ì¥
        pred_df = pd.DataFrame({"predictions": result["predictions"]})

        if "prediction_dates" in result:
            pred_df["prediction_date"] = result["prediction_dates"]

        if "confidence" in result:
            conf = result["confidence"]
            pred_df["confidence_mean"] = conf["mean"]
            pred_df["confidence_lower_95"] = conf["lower_95"]
            pred_df["confidence_upper_95"] = conf["upper_95"]

        safe_name = name.replace(" ", "_").lower()
        pred_df.to_csv(PREDICTIONS_DIR / f"{safe_name}.csv", index=False, encoding="utf-8-sig")

        # JSON ì €ì¥ (ë©”íƒ€ë°ì´í„° í¬í•¨)
        result_copy = result.copy()

        # numpy ë°°ì—´ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
        for key, value in result_copy.items():
            if isinstance(value, np.ndarray):
                result_copy[key] = value.tolist()
            elif isinstance(value, dict):
                for sub_key, sub_value in value.items():
                    if isinstance(sub_value, np.ndarray):
                        result_copy[key][sub_key] = sub_value.tolist()

        with open(PREDICTIONS_DIR / f"{safe_name}_metadata.json", "w", encoding="utf-8") as f:
            json.dump(result_copy, f, indent=2, ensure_ascii=False, default=str)

    def generate_prediction_report(self, prediction_names: List[str] = None) -> str:
        """
        ì˜ˆì¸¡ ë³´ê³ ì„œ ìƒì„±

        Args:
            prediction_names: ë³´ê³ ì„œì— í¬í•¨í•  ì˜ˆì¸¡ ì´ë¦„ ë¦¬ìŠ¤íŠ¸

        Returns:
            ë³´ê³ ì„œ í…ìŠ¤íŠ¸
        """
        logger.info("ğŸ“‹ ì˜ˆì¸¡ ë³´ê³ ì„œ ìƒì„± ì¤‘...")

        if prediction_names is None:
            prediction_names = list(self.predictions.keys()) + list(
                self.ensemble_predictions.keys()
            )

        report = f"""
# ì˜ˆì¸¡ ë³´ê³ ì„œ

## ğŸ“Š ì˜ˆì¸¡ ê°œìš”
- ë³´ê³ ì„œ ìƒì„±ì¼: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
- ì˜ˆì¸¡ ìˆ˜í–‰ ê±´ìˆ˜: {len(prediction_names)}
- ì‚¬ìš©ëœ ëª¨ë¸: {list(self.models.keys())}

## ğŸ”® ì˜ˆì¸¡ ê²°ê³¼ ìš”ì•½
"""

        for pred_name in prediction_names:
            pred_result = None
            if pred_name in self.predictions:
                pred_result = self.predictions[pred_name]
            elif pred_name in self.ensemble_predictions:
                pred_result = self.ensemble_predictions[pred_name]

            if pred_result:
                predictions = pred_result["predictions"]

                report += f"""
### {pred_name}
- **ì˜ˆì¸¡ ê°œìˆ˜**: {len(predictions)}ê°œ
- **ì˜ˆì¸¡ í‰ê· **: {np.mean(predictions):.0f}ëª…
- **ì˜ˆì¸¡ í‘œì¤€í¸ì°¨**: {np.std(predictions):.0f}ëª…
- **ì˜ˆì¸¡ ë²”ìœ„**: {np.min(predictions):.0f}ëª… ~ {np.max(predictions):.0f}ëª…
"""

                if "prediction_dates" in pred_result:
                    start_date = min(pred_result["prediction_dates"])
                    end_date = max(pred_result["prediction_dates"])
                    report += f"- **ì˜ˆì¸¡ ê¸°ê°„**: {start_date.strftime('%Y-%m')} ~ {end_date.strftime('%Y-%m')}\n"

                if "confidence" in pred_result:
                    conf = pred_result["confidence"]
                    report += f"- **ì‹ ë¢°êµ¬ê°„ í‰ê·  í­**: {np.mean(conf['upper_95'] - conf['lower_95']):.0f}ëª…\n"

        report += f"""

## ğŸ“ˆ ì£¼ìš” ì¸ì‚¬ì´íŠ¸
1. ì˜ˆì¸¡ ê²°ê³¼ì˜ ì „ë°˜ì ì¸ íŠ¸ë Œë“œ ë¶„ì„
2. ê³„ì ˆì„± ë° ì£¼ê¸°ì„± íŒ¨í„´ í™•ì¸
3. ëª¨ë¸ë³„ ì˜ˆì¸¡ ì„±í–¥ ì°¨ì´ ë¶„ì„
4. ë¶ˆí™•ì‹¤ì„± ìˆ˜ì¤€ í‰ê°€

## ğŸ’¡ ê¶Œì¥ì‚¬í•­
1. ì •ê¸°ì ì¸ ëª¨ë¸ ì¬í•™ìŠµ ìˆ˜í–‰
2. ì˜ˆì¸¡ ê²°ê³¼ì˜ ì§€ì†ì ì¸ ëª¨ë‹ˆí„°ë§
3. ì™¸ë¶€ ìš”ì¸ ë³€í™” ì‹œ ëª¨ë¸ ì—…ë°ì´íŠ¸ ê³ ë ¤
4. ì˜ˆì¸¡ ì •í™•ë„ í–¥ìƒì„ ìœ„í•œ íŠ¹ì„± ì¶”ê°€ ê²€í† 

---
ìƒì„±ì¼: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
"""

        # ë³´ê³ ì„œ ì €ì¥
        with open(RESULTS_DIR / "prediction_report.md", "w", encoding="utf-8") as f:
            f.write(report)

        logger.info("âœ… ì˜ˆì¸¡ ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ")

        return report


# ì‹¤í–‰ ì˜ˆì‹œ
if __name__ == "__main__":
    # ë°ì´í„° ë¡œë” ìƒì„±
    data_loader = DataLoader()

    # ì˜ˆì¸¡ ì‹¤í–‰ê¸° ìƒì„±
    predictor = Predictor(data_loader)

    # LSTM ëª¨ë¸ ë¡œë“œ (ì˜ˆì‹œ)
    lstm_model_path = LSTM_MODEL_DIR / "lstm_model.h5"
    if lstm_model_path.exists():
        predictor.load_model("LSTM", lstm_model_path, LSTMModel)

    # ë°ì´í„° ì¤€ë¹„
    X_train, y_train, X_val, y_val, X_test, y_test = data_loader.prepare_lstm_dataset()

    # ë‹¨ì¼ ëª¨ë¸ ì˜ˆì¸¡
    if "LSTM" in predictor.models:
        lstm_prediction = predictor.predict_single_model("LSTM", X_test, return_confidence=True)

        # ë¯¸ë˜ ì˜ˆì¸¡
        future_prediction = predictor.predict_future("LSTM", steps=12, use_recursive=True)

        # ì‹œê°í™”
        predictor.plot_predictions("LSTM")

        # ê²°ê³¼ ì €ì¥
        predictor.save_predictions()

        # ë³´ê³ ì„œ ìƒì„±
        report = predictor.generate_prediction_report()
        print(report)

    logger.info("âœ… ì˜ˆì¸¡ ì‹¤í–‰ê¸° í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
