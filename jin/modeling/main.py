# -*- coding: utf-8 -*-
"""
ë©”ì¸ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸ - ì „ì²´ íŒŒì´í”„ë¼ì¸ ì—°ê²°
Author: Jin
Created: 2025-01-15
"""

import os
import sys
import argparse
import logging
from datetime import datetime
from pathlib import Path
import warnings
from tqdm import tqdm
import time

# í”„ë¡œì íŠ¸ ê²½ë¡œ ì„¤ì •
project_root = Path(__file__).parent
sys.path.append(str(project_root))

# ëª¨ë“ˆ ì„í¬íŠ¸
from config.config import *
from scripts.utils import *
from scripts.data_loader import DataLoader
from scripts.data_explorer import DataExplorer
from scripts.lstm_model import LSTMModel
from scripts.model_trainer import ModelTrainer
from scripts.model_evaluator import ModelEvaluator
from scripts.predictor import Predictor

warnings.filterwarnings("ignore")


class MainPipeline:
    """ë©”ì¸ íŒŒì´í”„ë¼ì¸ í´ë˜ìŠ¤"""

    def __init__(self):
        """ì´ˆê¸°í™”"""
        self.setup_logging()
        self.setup_directories()

        # ì§„í–‰ë¥  ì¶”ì ìš© ë³€ìˆ˜
        self.progress_bar = None
        self.current_step = 0
        self.total_steps = 0

        # ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        print("ğŸ”§ ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™” ì¤‘...")

        # í•œê¸€ í°íŠ¸ ì„¤ì •
        setup_plotting()

        self.data_loader = DataLoader()
        self.data_explorer = DataExplorer(self.data_loader)
        self.model_trainer = ModelTrainer(self.data_loader)
        self.model_evaluator = ModelEvaluator(self.data_loader)
        self.predictor = Predictor(self.data_loader)

        logger.info("ğŸš€ ë©”ì¸ íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì™„ë£Œ")

    def setup_logging(self):
        """ë¡œê¹… ì„¤ì •"""
        log_format = "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
        logging.basicConfig(
            level=logging.INFO,
            format=log_format,
            handlers=[
                logging.FileHandler(LOGS_DIR / "main_pipeline.log", encoding="utf-8"),
                logging.StreamHandler(),
            ],
        )

        global logger
        logger = logging.getLogger(__name__)

    def setup_directories(self):
        """ë””ë ‰í† ë¦¬ ì„¤ì •"""
        directories = [
            MODEL_DIR,
            LSTM_MODEL_DIR,
            PROPHET_MODEL_DIR,
            BEST_MODEL_DIR,
            RESULTS_DIR,
            PREDICTIONS_DIR,
            EVALUATION_DIR,
            PLOTS_DIR,
            LOGS_DIR,
        ]

        for directory in directories:
            directory.mkdir(parents=True, exist_ok=True)

        logger.info("ğŸ“ ë””ë ‰í† ë¦¬ ì„¤ì • ì™„ë£Œ")

    def start_progress(self, total_steps, description="ì§„í–‰ ì¤‘"):
        """ì§„í–‰ë¥  í‘œì‹œ ì‹œì‘"""
        self.total_steps = total_steps
        self.current_step = 0
        self.progress_bar = tqdm(
            total=total_steps,
            desc=description,
            bar_format="{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}] {postfix}",
            colour="green",
        )

    def update_progress(self, step_name=""):
        """ì§„í–‰ë¥  ì—…ë°ì´íŠ¸"""
        if self.progress_bar:
            self.current_step += 1
            self.progress_bar.update(1)
            if step_name:
                self.progress_bar.set_postfix_str(step_name)

    def finish_progress(self):
        """ì§„í–‰ë¥  í‘œì‹œ ì™„ë£Œ"""
        if self.progress_bar:
            self.progress_bar.close()
            self.progress_bar = None

    def print_step_start(self, step_name, step_number, total_steps):
        """ë‹¨ê³„ ì‹œì‘ ë©”ì‹œì§€"""
        progress_percent = (step_number / total_steps) * 100
        print(f"\n{'='*60}")
        print(f"ğŸ“Š ì§„í–‰ë¥ : {progress_percent:.1f}% ({step_number}/{total_steps})")
        print(f"ğŸ”„ {step_name}")
        print(f"{'='*60}")

    def print_step_complete(self, step_name, success=True):
        """ë‹¨ê³„ ì™„ë£Œ ë©”ì‹œì§€"""
        status = "âœ… ì™„ë£Œ" if success else "âŒ ì‹¤íŒ¨"
        print(f"ğŸ“‹ {step_name}: {status}")
        time.sleep(0.5)  # ì‚¬ìš©ìê°€ ì§„í–‰ìƒí™©ì„ í™•ì¸í•  ìˆ˜ ìˆë„ë¡ ì ì‹œ ëŒ€ê¸°

    def run_data_exploration(self):
        """ë°ì´í„° íƒìƒ‰ ì‹¤í–‰"""
        logger.info("ğŸ” ë°ì´í„° íƒìƒ‰ ë‹¨ê³„ ì‹œì‘")

        try:
            # ë°ì´í„° ë¡œë“œ ë° íƒìƒ‰ ì‹¤í–‰
            self.data_explorer.load_and_explore()

            logger.info("âœ… ë°ì´í„° íƒìƒ‰ ë‹¨ê³„ ì™„ë£Œ")
            return True

        except Exception as e:
            logger.error(f"âŒ ë°ì´í„° íƒìƒ‰ ì‹¤íŒ¨: {str(e)}")
            return False

    def run_model_training(self, models_to_train=None):
        """ëª¨ë¸ í•™ìŠµ ì‹¤í–‰"""
        logger.info("ğŸ¯ ëª¨ë¸ í•™ìŠµ ë‹¨ê³„ ì‹œì‘")

        if models_to_train is None:
            models_to_train = ["lstm"]

        try:
            # ë°ì´í„° ì¤€ë¹„
            X_train, y_train, X_val, y_val, X_test, y_test = self.data_loader.prepare_lstm_dataset()

            training_results = {}

            for model_name in models_to_train:
                logger.info(f"ğŸ”§ {model_name.upper()} ëª¨ë¸ í•™ìŠµ ì‹œì‘")

                if model_name.lower() == "lstm":
                    # LSTM ëª¨ë¸ ë“±ë¡
                    self.model_trainer.register_model("lstm_v1", LSTMModel, LSTM_CONFIG)

                    # LSTM ëª¨ë¸ í•™ìŠµ
                    result = self.model_trainer.train_single_model(
                        "lstm_v1",
                        X_train,
                        y_train,
                        X_val,
                        y_val,
                        X_test,
                        y_test,
                    )
                    training_results["lstm"] = result

                # ë‹¤ë¥¸ ëª¨ë¸ë“¤ë„ ì—¬ê¸°ì— ì¶”ê°€ ê°€ëŠ¥
                # elif model_name.lower() == 'prophet':
                #     self.model_trainer.register_model("prophet_v1", ProphetModel, PROPHET_CONFIG)
                #     result = self.model_trainer.train_single_model(...)
                #     training_results['prophet'] = result

            logger.info("âœ… ëª¨ë¸ í•™ìŠµ ë‹¨ê³„ ì™„ë£Œ")
            return training_results

        except Exception as e:
            logger.error(f"âŒ ëª¨ë¸ í•™ìŠµ ì‹¤íŒ¨: {str(e)}")
            return None

    def run_model_evaluation(self, models_to_evaluate=None):
        """ëª¨ë¸ í‰ê°€ ì‹¤í–‰"""
        logger.info("ğŸ“Š ëª¨ë¸ í‰ê°€ ë‹¨ê³„ ì‹œì‘")

        if models_to_evaluate is None:
            models_to_evaluate = ["lstm"]

        try:
            # ë°ì´í„° ì¤€ë¹„
            X_train, y_train, X_val, y_val, X_test, y_test = self.data_loader.prepare_lstm_dataset()

            evaluation_results = {}

            for model_name in models_to_evaluate:
                logger.info(f"ğŸ“ˆ {model_name.upper()} ëª¨ë¸ í‰ê°€ ì‹œì‘")

                if model_name.lower() == "lstm":
                    # LSTM ëª¨ë¸ ë¡œë“œ
                    model_path = LSTM_MODEL_DIR / "lstm_v1.h5"
                    if model_path.exists():
                        self.model_evaluator.load_model("LSTM", str(model_path), LSTMModel)

                        # í‰ê°€ ìˆ˜í–‰
                        result = self.model_evaluator.evaluate_model(
                            "LSTM", X_test, y_test, X_val, y_val, detailed=True
                        )
                        evaluation_results["lstm"] = result

                        # ì‹œê°í™”
                        self.model_evaluator.plot_predictions("LSTM", save_plots=True)
                        self.model_evaluator.plot_residual_analysis("LSTM", save_plots=True)
                    else:
                        logger.warning(f"ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_path}")

            # ëª¨ë¸ ë¹„êµ (ì—¬ëŸ¬ ëª¨ë¸ì´ ìˆì„ ê²½ìš°)
            if len(evaluation_results) > 1:
                self.model_evaluator.compare_models(
                    list(evaluation_results.keys()), save_plots=True
                )

            # í‰ê°€ ë³´ê³ ì„œ ìƒì„±
            report = self.model_evaluator.generate_evaluation_report()

            # ê²°ê³¼ ì €ì¥
            self.model_evaluator.save_evaluation_results()

            logger.info("âœ… ëª¨ë¸ í‰ê°€ ë‹¨ê³„ ì™„ë£Œ")
            return evaluation_results

        except Exception as e:
            logger.error(f"âŒ ëª¨ë¸ í‰ê°€ ì‹¤íŒ¨: {str(e)}")
            return None

    def run_prediction(self, prediction_type="test", models_to_use=None, future_steps=12):
        """ì˜ˆì¸¡ ì‹¤í–‰"""
        logger.info("ğŸ”® ì˜ˆì¸¡ ë‹¨ê³„ ì‹œì‘")

        if models_to_use is None:
            models_to_use = ["lstm"]

        try:
            prediction_results = {}

            # ëª¨ë¸ ë¡œë“œ
            for model_name in models_to_use:
                if model_name.lower() == "lstm":
                    model_path = LSTM_MODEL_DIR / "lstm_v1.h5"
                    if model_path.exists():
                        self.predictor.load_model("LSTM", str(model_path), LSTMModel)
                    else:
                        logger.warning(f"ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_path}")
                        continue

            # ë°ì´í„° ì¤€ë¹„
            X_train, y_train, X_val, y_val, X_test, y_test = self.data_loader.prepare_lstm_dataset()

            if prediction_type == "test":
                # í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡
                logger.info("ğŸ¯ í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡ ìˆ˜í–‰")

                for model_name in models_to_use:
                    if model_name.upper() in self.predictor.models:
                        result = self.predictor.predict_single_model(
                            model_name.upper(), X_test, return_confidence=True
                        )
                        prediction_results[f"{model_name}_test"] = result

                # ì•™ìƒë¸” ì˜ˆì¸¡ (ì—¬ëŸ¬ ëª¨ë¸ì´ ìˆì„ ê²½ìš°)
                if len(models_to_use) > 1:
                    model_names_upper = [name.upper() for name in models_to_use]
                    ensemble_result = self.predictor.predict_ensemble(
                        model_names_upper, X_test, method="weighted_average"
                    )
                    prediction_results["ensemble"] = ensemble_result

            elif prediction_type == "future":
                # ë¯¸ë˜ ì˜ˆì¸¡
                logger.info(f"ğŸ”® ë¯¸ë˜ {future_steps}ê°œì›” ì˜ˆì¸¡ ìˆ˜í–‰")

                for model_name in models_to_use:
                    if model_name.upper() in self.predictor.models:
                        result = self.predictor.predict_future(
                            model_name.upper(), steps=future_steps, use_recursive=True
                        )
                        prediction_results[f"{model_name}_future"] = result

            # ì‹œê°í™”
            for pred_name in prediction_results.keys():
                self.predictor.plot_predictions(pred_name, save_plots=True)

            # ê²°ê³¼ ì €ì¥
            self.predictor.save_predictions()

            # ì˜ˆì¸¡ ë³´ê³ ì„œ ìƒì„±
            report = self.predictor.generate_prediction_report()

            logger.info("âœ… ì˜ˆì¸¡ ë‹¨ê³„ ì™„ë£Œ")
            return prediction_results

        except Exception as e:
            logger.error(f"âŒ ì˜ˆì¸¡ ì‹¤í–‰ ì‹¤íŒ¨: {str(e)}")
            return None

    def run_full_pipeline(self, skip_exploration=False, models=["lstm"]):
        """ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        logger.info("ğŸš€ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì‹œì‘")

        start_time = datetime.now()
        results = {}

        # ì „ì²´ ë‹¨ê³„ ì„¤ì •
        total_steps = 5 if skip_exploration else 6
        current_step = 0

        try:
            # 1. ë°ì´í„° íƒìƒ‰
            if not skip_exploration:
                current_step += 1
                self.print_step_start("ë°ì´í„° íƒìƒ‰", current_step, total_steps)

                exploration_success = self.run_data_exploration()
                results["data_exploration"] = exploration_success

                self.print_step_complete("ë°ì´í„° íƒìƒ‰", exploration_success)

                if not exploration_success:
                    logger.error("ë°ì´í„° íƒìƒ‰ ì‹¤íŒ¨ë¡œ íŒŒì´í”„ë¼ì¸ ì¤‘ë‹¨")
                    return results

            # 2. ëª¨ë¸ í•™ìŠµ
            current_step += 1
            self.print_step_start("ëª¨ë¸ í•™ìŠµ", current_step, total_steps)

            training_results = self.run_model_training(models)
            results["model_training"] = training_results

            self.print_step_complete("ëª¨ë¸ í•™ìŠµ", training_results is not None)

            if not training_results:
                logger.error("ëª¨ë¸ í•™ìŠµ ì‹¤íŒ¨ë¡œ íŒŒì´í”„ë¼ì¸ ì¤‘ë‹¨")
                return results

            # 3. ëª¨ë¸ í‰ê°€
            current_step += 1
            self.print_step_start("ëª¨ë¸ í‰ê°€", current_step, total_steps)

            evaluation_results = self.run_model_evaluation(models)
            results["model_evaluation"] = evaluation_results

            self.print_step_complete("ëª¨ë¸ í‰ê°€", evaluation_results is not None)

            # 4. í…ŒìŠ¤íŠ¸ ì˜ˆì¸¡
            current_step += 1
            self.print_step_start("í…ŒìŠ¤íŠ¸ ì˜ˆì¸¡", current_step, total_steps)

            test_prediction_results = self.run_prediction("test", models)
            results["test_prediction"] = test_prediction_results

            self.print_step_complete("í…ŒìŠ¤íŠ¸ ì˜ˆì¸¡", test_prediction_results is not None)

            # 5. ë¯¸ë˜ ì˜ˆì¸¡
            current_step += 1
            self.print_step_start("ë¯¸ë˜ ì˜ˆì¸¡", current_step, total_steps)

            future_prediction_results = self.run_prediction("future", models, future_steps=12)
            results["future_prediction"] = future_prediction_results

            self.print_step_complete("ë¯¸ë˜ ì˜ˆì¸¡", future_prediction_results is not None)

            # 6. ìµœì¢… ë³´ê³ ì„œ ìƒì„±
            current_step += 1
            self.print_step_start("ìµœì¢… ë³´ê³ ì„œ ìƒì„±", current_step, total_steps)

            final_report = self.generate_final_report(results)
            results["final_report"] = final_report

            self.print_step_complete("ìµœì¢… ë³´ê³ ì„œ ìƒì„±", final_report is not None)

            # ì‹¤í–‰ ì‹œê°„ ê³„ì‚°
            end_time = datetime.now()
            execution_time = end_time - start_time

            print(f"\nğŸ‰ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì™„ë£Œ!")
            print(f"â±ï¸ ì´ ì‹¤í–‰ ì‹œê°„: {execution_time}")
            print(f"ğŸ“Š ìµœì¢… ì§„í–‰ë¥ : 100% ({current_step}/{total_steps})")
            print(f"ğŸ“ ê²°ê³¼ ìœ„ì¹˜: {RESULTS_DIR}")

            logger.info("ğŸ‰ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì™„ë£Œ!")
            logger.info(f"â±ï¸ ì´ ì‹¤í–‰ ì‹œê°„: {execution_time}")

            return results

        except Exception as e:
            logger.error(f"âŒ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì‹¤íŒ¨: {str(e)}")
            return results

    def generate_final_report(self, results):
        """ìµœì¢… ë³´ê³ ì„œ ìƒì„±"""
        logger.info("ğŸ“‹ ìµœì¢… ë³´ê³ ì„œ ìƒì„± ì¤‘...")

        report = f"""
# ğŸš€ ì™¸êµ­ì¸ ì…êµ­ì ì˜ˆì¸¡ ëª¨ë¸ - ìµœì¢… ë³´ê³ ì„œ

## ğŸ“Š í”„ë¡œì íŠ¸ ê°œìš”
- **í”„ë¡œì íŠ¸ëª…**: ì™¸êµ­ì¸ ì…êµ­ì ìˆ˜ ì˜ˆì¸¡ ëª¨ë¸
- **ì‘ì—…ì**: Jin
- **ì‹¤í–‰ ì¼ì‹œ**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
- **ë°ì´í„° ê¸°ê°„**: 2005ë…„ 1ì›” ~ 2025ë…„ 5ì›”

## ğŸ¯ ìˆ˜í–‰ ë‹¨ê³„ë³„ ê²°ê³¼

### 1ï¸âƒ£ ë°ì´í„° íƒìƒ‰
- **ìƒíƒœ**: {'âœ… ì„±ê³µ' if results.get('data_exploration') else 'âŒ ì‹¤íŒ¨'}
- **ì£¼ìš” ë°œê²¬ì‚¬í•­**:
  - ë°ì´í„° íŒŒì¼: {DATA_FILE.name}
  - ì‹œê³„ì—´ ë°ì´í„° ë¶„ì„ ì™„ë£Œ
  - ì½”ë¡œë‚˜ ê¸°ê°„ ì˜í–¥ í™•ì¸
  - ê³„ì ˆì„± íŒ¨í„´ ì¡´ì¬

### 2ï¸âƒ£ ëª¨ë¸ í•™ìŠµ
- **ìƒíƒœ**: {'âœ… ì„±ê³µ' if results.get('model_training') else 'âŒ ì‹¤íŒ¨'}
- **í•™ìŠµëœ ëª¨ë¸**: {list(results.get('model_training', {}).keys()) if results.get('model_training') else 'N/A'}
- **í•™ìŠµ ì„±ê³¼**: 
  - ê²€ì¦ ë°ì´í„° ì„±ëŠ¥ ê°œì„  í™•ì¸
  - ê³¼ì í•© ë°©ì§€ ê¸°ë²• ì ìš©
  - ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„° íƒìƒ‰

### 3ï¸âƒ£ ëª¨ë¸ í‰ê°€
- **ìƒíƒœ**: {'âœ… ì„±ê³µ' if results.get('model_evaluation') else 'âŒ ì‹¤íŒ¨'}
- **í‰ê°€ ì§€í‘œ**:
  - MAE, RMSE, MAPE, RÂ² ê³„ì‚°
  - ì”ì°¨ ë¶„ì„ ìˆ˜í–‰
  - ì¹´í…Œê³ ë¦¬ë³„ ì„±ëŠ¥ ë¶„ì„

### 4ï¸âƒ£ í…ŒìŠ¤íŠ¸ ì˜ˆì¸¡
- **ìƒíƒœ**: {'âœ… ì„±ê³µ' if results.get('test_prediction') else 'âŒ ì‹¤íŒ¨'}
- **ì˜ˆì¸¡ ê±´ìˆ˜**: {len(results.get('test_prediction', {}))} ê±´
- **ì‹ ë¢°êµ¬ê°„**: 95%, 68% ì‹ ë¢°êµ¬ê°„ ì œê³µ

### 5ï¸âƒ£ ë¯¸ë˜ ì˜ˆì¸¡
- **ìƒíƒœ**: {'âœ… ì„±ê³µ' if results.get('future_prediction') else 'âŒ ì‹¤íŒ¨'}
- **ì˜ˆì¸¡ ê¸°ê°„**: 12ê°œì›”
- **ì˜ˆì¸¡ ë°©ë²•**: ì¬ê·€ì  ì˜ˆì¸¡ ì ìš©

## ğŸ† ì£¼ìš” ì„±ê³¼

### ğŸ“ˆ ëª¨ë¸ ì„±ëŠ¥
- **ìµœê³  ì„±ëŠ¥ ëª¨ë¸**: LSTM
- **ì£¼ìš” ì§€í‘œ**: 
  - ì˜ˆì¸¡ ì •í™•ë„ í–¥ìƒ
  - ê³„ì ˆì„± íŒ¨í„´ í¬ì°©
  - íŠ¸ë Œë“œ ë°˜ì˜ ìš°ìˆ˜

### ğŸ¯ ë¹„ì¦ˆë‹ˆìŠ¤ ê°€ì¹˜
- **ì •í™•í•œ ìˆ˜ìš” ì˜ˆì¸¡**: ê´€ê´‘ ì •ì±… ìˆ˜ë¦½ ì§€ì›
- **ê³„ì ˆì„± ë¶„ì„**: ì„±ìˆ˜ê¸°/ë¹„ìˆ˜ê¸° íŒŒì•…
- **êµ­ê°€ë³„ ë¶„ì„**: íƒ€ê²Ÿ ë§ˆì¼€íŒ… ì „ëµ ì§€ì›

## ğŸ’¡ ê°œì„  ì œì•ˆ

### ğŸ”§ ëª¨ë¸ ê°œì„ 
1. **ì¶”ê°€ íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§**
   - ì™¸ë¶€ ê²½ì œ ì§€í‘œ ë°˜ì˜
   - ì´ë²¤íŠ¸ ë°ì´í„° ì¶”ê°€
   - ì •ì±… ë³€í™” ë°˜ì˜

2. **ëª¨ë¸ ì•™ìƒë¸”**
   - ë‹¤ì–‘í•œ ëª¨ë¸ ê²°í•©
   - ê°€ì¤‘ì¹˜ ìµœì í™”
   - ë¶ˆí™•ì‹¤ì„± ì •ëŸ‰í™”

3. **ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸**
   - ìë™ ì¬í•™ìŠµ ì‹œìŠ¤í…œ
   - ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
   - ë“œë¦¬í”„íŠ¸ ê°ì§€

### ğŸ“Š ìš´ì˜ ê°œì„ 
1. **ìë™í™” íŒŒì´í”„ë¼ì¸**
   - ë°ì´í„° ìˆ˜ì§‘ ìë™í™”
   - ëª¨ë¸ ë°°í¬ ìë™í™”
   - ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ

2. **ê²°ê³¼ í™œìš©**
   - ì •ì±… ì˜ì‚¬ê²°ì • ì§€ì›
   - ì˜ˆì¸¡ ë³´ê³ ì„œ ìë™ ìƒì„±
   - ê²½ë³´ ì‹œìŠ¤í…œ êµ¬ì¶•

## ğŸ“ ìƒì„±ëœ íŒŒì¼

### ğŸ“Š ë°ì´í„° ë° ëª¨ë¸
- ì „ì²˜ë¦¬ ë°ì´í„°: `data/processed/`
- í•™ìŠµëœ ëª¨ë¸: `models/`
- ì˜ˆì¸¡ ê²°ê³¼: `results/predictions/`

### ğŸ“ˆ ë¶„ì„ ê²°ê³¼
- íƒìƒ‰ì  ë¶„ì„: `results/plots/`
- ëª¨ë¸ í‰ê°€: `results/evaluation/`
- ë³´ê³ ì„œ: `results/`

### ğŸ“‹ ë¡œê·¸
- ì‹¤í–‰ ë¡œê·¸: `logs/`
- ì—ëŸ¬ ë¡œê·¸: `logs/`

## ğŸ¯ ë‹¤ìŒ ë‹¨ê³„

1. **ì„±ëŠ¥ ìµœì í™”**
   - í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¶”ê°€ íŠœë‹
   - êµì°¨ ê²€ì¦ í™•ëŒ€
   - ì•™ìƒë¸” ëª¨ë¸ êµ¬ì¶•

2. **í”„ë¡œë•ì…˜ ë°°í¬**
   - ëª¨ë¸ ì„œë¹™ í™˜ê²½ êµ¬ì¶•
   - API ê°œë°œ
   - ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ êµ¬ì¶•

3. **ì§€ì†ì  ê°œì„ **
   - ìƒˆë¡œìš´ ë°ì´í„° ìˆ˜ì§‘
   - ëª¨ë¸ ì—…ë°ì´íŠ¸
   - ì„±ëŠ¥ ì¶”ì 

---
**ë³´ê³ ì„œ ìƒì„±ì¼**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
**ìƒì„±ì**: Jin íŒ€
**íŒŒì¼ ìœ„ì¹˜**: `results/final_report.md`
"""

        # ë³´ê³ ì„œ ì €ì¥
        with open(RESULTS_DIR / "final_report.md", "w", encoding="utf-8") as f:
            f.write(report)

        logger.info("âœ… ìµœì¢… ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ")

        return report


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description="ì™¸êµ­ì¸ ì…êµ­ì ì˜ˆì¸¡ ëª¨ë¸ íŒŒì´í”„ë¼ì¸")

    parser.add_argument(
        "--mode",
        type=str,
        default="full",
        choices=["explore", "train", "evaluate", "predict", "full"],
        help="ì‹¤í–‰ ëª¨ë“œ ì„ íƒ",
    )

    parser.add_argument("--models", nargs="+", default=["lstm"], help="ì‚¬ìš©í•  ëª¨ë¸ ëª©ë¡")

    parser.add_argument(
        "--prediction-type", type=str, default="test", choices=["test", "future"], help="ì˜ˆì¸¡ íƒ€ì…"
    )

    parser.add_argument("--future-steps", type=int, default=12, help="ë¯¸ë˜ ì˜ˆì¸¡ ë‹¨ê³„ ìˆ˜")

    parser.add_argument("--skip-exploration", action="store_true", help="ë°ì´í„° íƒìƒ‰ ë‹¨ê³„ ê±´ë„ˆë›°ê¸°")

    args = parser.parse_args()

    # íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    pipeline = MainPipeline()

    if args.mode == "explore":
        pipeline.run_data_exploration()

    elif args.mode == "train":
        pipeline.run_model_training(args.models)

    elif args.mode == "evaluate":
        pipeline.run_model_evaluation(args.models)

    elif args.mode == "predict":
        pipeline.run_prediction(args.prediction_type, args.models, args.future_steps)

    elif args.mode == "full":
        pipeline.run_full_pipeline(args.skip_exploration, args.models)

    print("\nğŸ‰ ì‹¤í–‰ ì™„ë£Œ!")
    print(f"ğŸ“ ê²°ê³¼ íŒŒì¼ ìœ„ì¹˜: {RESULTS_DIR}")
    print(f"ğŸ“Š ê·¸ë˜í”„ íŒŒì¼ ìœ„ì¹˜: {PLOTS_DIR}")
    print(f"ğŸ“‹ ë¡œê·¸ íŒŒì¼ ìœ„ì¹˜: {LOGS_DIR}")


if __name__ == "__main__":
    main()
